{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.base import BaseEstimator\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(target, classes):\n",
    "    return (classes == target[:, None]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elcl:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X_train, y_train, num_classes, max_elems):\n",
    "        self.classes = num_classes\n",
    "        self.sigmas = defaultdict(list)\n",
    "        self.weights = defaultdict(list)\n",
    "\n",
    "        for c in range(self.classes):\n",
    "            y_for_dualization = y_train[y_train != c]\n",
    "            X_for_dualization = X_train[y_train != c]\n",
    "            os.system('touch \"in.txt\"')\n",
    "            with open('in.txt', 'w') as file:\n",
    "                file.write(' '.join([str(elem) for elem in max_elems]) + '\\n')\n",
    "                for obj in X_for_dualization:\n",
    "                    file.write(' '.join([str(elem) for elem in obj]) + '\\n')\n",
    "\n",
    "            #дуализация\n",
    "            #print('dual start')\n",
    "            os.system(\"g++ -std=c++17 -O3 final.cpp -o final && ./final\")\n",
    "            #print('dual end')\n",
    "            coverages = pd.read_csv('out.csv', header=None).values\n",
    "            sigmas = pd.read_csv('out_sigma.csv', header=None).values\n",
    "            os.system(\"rm out.csv\")\n",
    "            os.system(\"rm out_sigma.csv\")\n",
    "            \n",
    "            for i in range(len(max_elems)):\n",
    "                sigmas[:, i][coverages[:, i] == 0] = max_elems[i]\n",
    "            for i in range(len(max_elems), X_train.shape[1]):\n",
    "                sigmas[:, i][coverages[:, i] == 0] = max_elems[i - len(max_elems)]\n",
    "\n",
    "            #sigmas[coverages == 0] = self.max_sigma\n",
    "            #print('here')\n",
    "            #проверить на представительность\n",
    "            for elcl, pos in zip(sigmas, coverages):\n",
    "                good = 0\n",
    "                for obj in X_train[y_train == c]:\n",
    "                    if (elcl[np.where(pos == 1)[0]] >= obj[np.where(pos == 1)[0]]).all():\n",
    "                        good += 1\n",
    "                if good:\n",
    "                    self.sigmas[c].append(elcl)\n",
    "                    self.weights[c].append(good / np.sum([y_train == c]))\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        #голосование \n",
    "        self.res = np.zeros((X.shape[0], self.classes))\n",
    "        for c in range(self.classes):\n",
    "            for i, obj in enumerate(X):\n",
    "\n",
    "                for elcl, w in zip(self.sigmas[c], self.weights[c]):\n",
    "                    if (obj <= elcl).all():\n",
    "                        self.res[i][c] += w #вес - число прецедентов с таким эл кл\n",
    "\n",
    "            if len(self.sigmas[c]):\n",
    "                pass\n",
    "                #self.res[:, c] /= len(self.sigmas[c])\n",
    "        return self.res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_inverse(X, size):\n",
    "    #a = np.arange(X.shape[1])\n",
    "    #ind = np.random.choice(a, size=size, replace=False)\n",
    "    ind = np.arange(size)\n",
    "    newX = np.zeros((X.shape[0], X.shape[1] + len(ind)), dtype=np.int)\n",
    "    newX[:, : X.shape[1]] = X\n",
    "    for j, i in enumerate(ind):\n",
    "        newX[:, X.shape[1] + j] = np.max(X[:, i]) - X[:, i]\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(X, thr):\n",
    "    newX = X.copy()\n",
    "    inv = X.shape[1] - 1\n",
    "    c = 0\n",
    "    for i in range(X.shape[1]):\n",
    "        encode = {k:j for j, k in enumerate(sorted(np.unique(X[:, i])))}\n",
    "        if max(encode.values()) < thr:\n",
    "            new_i = inv\n",
    "            inv -= 1\n",
    "        else:\n",
    "            new_i = c\n",
    "            c += 1\n",
    "        for j in range(X.shape[0]):\n",
    "            newX[j, new_i] = encode[X[j, i]]\n",
    "\n",
    "    return newX, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging_elcl(BaseEstimator):\n",
    "    def __init__(self, max_elems, inv_feat, feature_subset=1):\n",
    "        self.max_elems = max_elems\n",
    "        self.feature_subset=feature_subset\n",
    "        self.inv_feat = inv_feat\n",
    "        \n",
    "    def fit(self, X, y):        \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.classes = np.max(y) + 1\n",
    "    def predict(self, X_test, num_runs=10):\n",
    "        res = np.zeros((X_test.shape[0], self.classes))\n",
    "        for i in trange(num_runs):\n",
    "            \n",
    "            train_idx = np.random.randint(0, self.X_train.shape[0], self.X_train.shape[0])\n",
    "            new_X_train = self.X_train[train_idx]\n",
    "            new_y_train = self.y_train[train_idx]\n",
    "            new_X_test = X_test\n",
    "            tmp_max_elems = self.max_elems\n",
    "            if self.feature_subset != 1:\n",
    "                \n",
    "                tmp = int((self.X_train.shape[1] - self.inv_feat) * self.feature_subset)\n",
    "                feature_idx = np.sort(np.random.choice(self.X_train.shape[1] - self.inv_feat, tmp, \n",
    "                                                       replace=False))\n",
    "                tmp_max_elems = self.max_elems[feature_idx]\n",
    "                \n",
    "                feature_idx = np.append(feature_idx, feature_idx + self.X_train.shape[1] - self.inv_feat)\n",
    "                feature_idx = feature_idx[feature_idx < new_X_train.shape[1]]\n",
    "                new_X_train = new_X_train[:, feature_idx]\n",
    "                new_X_test = X_test[:, feature_idx]\n",
    "\n",
    "                               \n",
    "            \n",
    "            elcl = Elcl()\n",
    "            elcl.fit(new_X_train, new_y_train, self.classes, tmp_max_elems)\n",
    "            \n",
    "            res += elcl.predict(new_X_test)\n",
    "\n",
    "        return np.argmax(res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging_trees(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    def predict(self, X_test, num_runs=10):\n",
    "\n",
    "        res = np.zeros((X_test.shape[0], np.max(self.y_train) + 1))\n",
    "        for i in range(num_runs):\n",
    "\n",
    "            train_idx = np.random.randint(0, self.X_train.shape[0], self.X_train.shape[0])\n",
    "            new_X_train = self.X_train[train_idx]\n",
    "            new_y_train = self.y_train[train_idx]\n",
    "\n",
    "            tree = DecisionTreeClassifier(random_state=0, max_depth=5)\n",
    "            tree.fit(new_X_train, new_y_train)\n",
    "            res += tree.predict_proba(X_test)\n",
    "\n",
    "        return np.argmax(res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, X_test):\n",
    "    forest = RandomForestClassifier()\n",
    "    forest.fit(X_train, y_train)\n",
    "    return forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ph = pd.read_csv('datasets_81236_188723_ph-data.csv')\n",
    "X = data_ph.drop(columns=['label']).values.astype(int)\n",
    "y = data_ph[['label']].values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('m = 436', 'k = 185', 'n = 6')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1, c = enc(X, thr=3)\n",
    "inv_feat = X1.shape[1]\n",
    "Xd = add_inverse(X1, inv_feat)\n",
    "\n",
    "cv = 3\n",
    "feature_subset = 1\n",
    "'m = ' + str(math.ceil(Xd.shape[0]*(cv-1)/cv)), 'k = ' + str(np.max(Xd)),\\\n",
    "'n = ' + str(int(Xd.shape[1] / 2 * feature_subset ) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bagging_elcl(np.max(X1, axis=0), inv_feat=inv_feat, feature_subset=feature_subset)\n",
    "ans = cross_val_predict(model, Xd, y, cv=cv)\n",
    "\n",
    "model = Bagging_trees()\n",
    "ans_tree = cross_val_predict(model, X, y)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "ans_forest = cross_val_predict(model, X, y)\n",
    "\n",
    "np.mean(ans == y), np.mean(ans_tree == y), np.mean(ans_forest == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5249945307372565, 0.8482279588711441, 0.853150295340188)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.arange(len(np.unique(y)))\n",
    "tmp =  ohe(y, classes)\n",
    "\n",
    "roc_auc_score(tmp, ohe(ans, classes), average='micro'), roc_auc_score(tmp, ohe(ans_tree, classes), average='micro'), \\\n",
    "roc_auc_score(tmp, ohe(ans_forest, classes), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ohe() missing 1 required positional argument: 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-06df1ae93346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mohe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_forest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ohe() missing 1 required positional argument: 'classes'"
     ]
    }
   ],
   "source": [
    "classes = np.arange(len(np.unique(y_test)))\n",
    "tmp =  ohe(y_test, classes)\n",
    "\n",
    "roc_auc_score(tmp, ohe(ans), average='macro'), roc_auc_score(tmp, ohe(ans_tree), average='macro'), \\\n",
    "roc_auc_score(tmp, ohe(ans_forest), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), 564)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_heart = pd.read_csv('datasets_33180_43520_heart.csv')\n",
    "\n",
    "X = data_heart.drop(columns=['target']).values.astype(int)\n",
    "y = data_heart[['target']].values[:, 0]\n",
    "\n",
    "X.shape, np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('m = 1152', 'k = 4', 'n = 6')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1, c = enc(X, thr=20)\n",
    "inv_feat = X1.shape[1]\n",
    "Xd = add_inverse(X1, inv_feat)\n",
    "cv = 3\n",
    "feature_subset = 0.5\n",
    "'m = ' + str(math.ceil(Xd.shape[0]*(cv-1)/cv)), 'k = ' + str(np.max(Xd) + 1),\\\n",
    "'n = ' + str(int(Xd.shape[1] / 2 * feature_subset ) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27546d4d42e4ff3879c8584e314ca24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e280319e7f4240a462b81837be22cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838411c4400843e787308d82d1a38140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8613861386138614, 0.6996699669966997, 0.8085808580858086)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Bagging_elcl(np.max(X1, axis=0), inv_feat=inv_feat, feature_subset=feature_subset)\n",
    "ans = cross_val_predict(model, Xd, y, cv=cv)\n",
    "\n",
    "model = Bagging_trees()\n",
    "ans_tree = cross_val_predict(model, X, y)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "ans_forest = cross_val_predict(model, X, y)\n",
    "\n",
    "np.mean(ans ==  y), np.mean(ans_tree == y), np.mean(ans_forest == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.857905138339921, 0.6940052700922267, 0.805862977602108)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.arange(len(np.unique(y)))\n",
    "tmp =  ohe(y, classes)\n",
    "\n",
    "roc_auc_score(tmp, ohe(ans, classes), average='macro'), roc_auc_score(tmp, ohe(ans_tree, classes), average='macro'), \\\n",
    "roc_auc_score(tmp, ohe(ans_forest, classes), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dermatology = pd.read_csv('dermatology.csv')\n",
    "\n",
    "X = data_dermatology.drop(columns=['class']).values.astype(int)\n",
    "y = data_dermatology[['class']].values[:, 0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 34)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('m = 1152', 'k = 4', 'n = 6')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1, c = enc(X, thr=20)\n",
    "inv_feat = X1.shape[1]\n",
    "Xd = add_inverse(X1, inv_feat)\n",
    "cv = 3\n",
    "feature_subset = 0.5\n",
    "'m = ' + str(math.ceil(Xd.shape[0]*(cv-1)/cv)), 'k = ' + str(np.max(Xd)+ 1),\\\n",
    "'n = ' + str(int(Xd.shape[1] / 2 * feature_subset ) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bagging_elcl(np.max(X1, axis=0), inv_feat=inv_feat, feature_subset=feature_subset)\n",
    "ans = cross_val_predict(model, Xd, y, cv=cv)\n",
    "\n",
    "model = Bagging_trees()\n",
    "ans_tree = cross_val_predict(model, X, y, cv=cv)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "ans_forest = cross_val_predict(model, X, y, cv=cv)\n",
    "\n",
    "np.mean(ans ==  y), np.mean(ans_tree == y), np.mean(ans_forest == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.arange(len(np.unique(y)))\n",
    "tmp =  ohe(y, classes)\n",
    "\n",
    "roc_auc_score(tmp, ohe(ans, classes), average='macro'), roc_auc_score(tmp, ohe(ans_tree, classes), average='macro'), \\\n",
    "roc_auc_score(tmp, ohe(ans_forest, classes), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_car = pd.read_csv('car.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_car.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh' 'high' 'med' 'low']\n",
      "['vhigh' 'high' 'med' 'low']\n",
      "['2' '3' '4' '5more']\n",
      "['2' '4' 'more']\n",
      "['small' 'med' 'big']\n",
      "['low' 'med' 'high']\n",
      "['unacc' 'acc' 'vgood' 'good']\n"
     ]
    }
   ],
   "source": [
    "for i in range(data_car.shape[1]):\n",
    "    print(data_car[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_car = data_car.replace('low', 0)\n",
    "data_car = data_car.replace('med', 1)\n",
    "data_car = data_car.replace('high', 2)\n",
    "data_car = data_car.replace('vhigh', 3)\n",
    "\n",
    "data_car = data_car.replace('5more', 5)\n",
    "data_car = data_car.replace('more', 5)\n",
    "\n",
    "data_car = data_car.replace('small', 0)\n",
    "data_car = data_car.replace('big', 2)\n",
    "\n",
    "data_car = data_car.replace('unacc', 0)\n",
    "data_car = data_car.replace('acc', 1)\n",
    "data_car = data_car.replace('good', 2)\n",
    "data_car = data_car.replace('vgood', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_car.values[:, :6].astype(int)\n",
    "y = data_car[6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('m = 1383', 'k = 4', 'n = 12')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1, c = enc(X, thr=3)\n",
    "inv_feat = X1.shape[1]\n",
    "Xd = add_inverse(X1, inv_feat)\n",
    "cv = 5\n",
    "feature_subset = 1\n",
    "'m = ' + str(math.ceil(Xd.shape[0]*(cv-1)/cv)), 'k = ' + str(np.max(Xd) + 1),\\\n",
    "'n = ' + str(int(Xd.shape[1] / 2 * feature_subset ) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284e603bdc894004b5deeb2a5e5407d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65128d5890f644e3962f9e5bb53eb0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a588a5af8bb246cb848137048463d573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd80681aac974551b90ddc304812145e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a7182dcbbf4b9f8caa2c7e76b5dbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8078703703703703, 0.8298611111111112, 0.8211805555555556)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Bagging_elcl(np.max(X1, axis=0), inv_feat=inv_feat, feature_subset=feature_subset)\n",
    "ans = cross_val_predict(model, Xd, y, cv=cv)\n",
    "\n",
    "model = Bagging_trees()\n",
    "ans_tree = cross_val_predict(model, X, y, cv=cv)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "ans_forest = cross_val_predict(model, X, y, cv=cv)\n",
    "\n",
    "np.mean(ans ==  y), np.mean(ans_tree == y), np.mean(ans_forest == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.776968534133446, 0.7424211079532403, 0.7895742378271532)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.arange(len(np.unique(y)))\n",
    "tmp =  ohe(y, classes)\n",
    "\n",
    "roc_auc_score(tmp, ohe(ans, classes), average='macro'), roc_auc_score(tmp, ohe(ans_tree, classes), average='macro'), \\\n",
    "roc_auc_score(tmp, ohe(ans_forest, classes), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
